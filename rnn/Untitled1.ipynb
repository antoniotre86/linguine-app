{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Embedding, SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/rnn'\n",
    "\n",
    "# training:\n",
    "epochs = 16 \n",
    "batch_size = 128\n",
    "training_size = 10**5\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 32 \n",
    "n_unique_words = 10000 \n",
    "max_review_length = 100 # lowered due to vanishing gradient over time\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2 \n",
    "\n",
    "# RNN layer architecture:\n",
    "n_rnn = 256 \n",
    "drop_rnn = 0.2\n",
    "\n",
    "\n",
    "# dense layer architecture: \n",
    "# n_dense = 256\n",
    "# dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = urllib3.PoolManager()\n",
    "# resp = html.request('GET', 'https://github.com/dwyl/english-words/blob/master/words.txt?raw=true')\n",
    "\n",
    "# eng_words = resp.data.decode('utf-8').split('\\n')\n",
    "# eng_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR + 'english_words.pk', 'rb') as foo:\n",
    "    eng_words = pickle.load(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zwinglianist',\n",
       " 'zwitter',\n",
       " 'zwitterion',\n",
       " 'zwitterionic',\n",
       " 'Zwolle',\n",
       " 'Zworykin',\n",
       " 'ZZ',\n",
       " 'zZt',\n",
       " 'ZZZ',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp1 = html.request('GET', 'https://github.com/napolux/paroleitaliane/blob/master/paroleitaliane/660000_parole_italiane.txt?raw=true')\n",
    "\n",
    "# it_words = resp1.data.decode('utf-8').split('\\n')\n",
    "# it_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'italian_words.pk'), 'rb') as foo:\n",
    "    it_words = pickle.load(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zwinglianesimo',\n",
       " 'zwingliani',\n",
       " 'zwingliano',\n",
       " 'zwinglismi',\n",
       " 'zwinglismo',\n",
       " 'zwinglista',\n",
       " 'zwingliste',\n",
       " 'zwinglisti',\n",
       " 'zzz',\n",
       " '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get character dictionary\n",
    "\n",
    "eng_ch_vocab = set([c for w in eng_words for c in w])\n",
    "it_ch_vocab = set([c for w in it_words for c in w])\n",
    "\n",
    "vocab = sorted(list(eng_ch_vocab.union(it_ch_vocab)))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/vocab.json', 'w') as foow:\n",
    "    json.dump(vocab, foow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_to_letter_id(w):\n",
    "    out = [vocab.index(c) for c in w]\n",
    "    return out\n",
    "\n",
    "def convert_dataset_to_idx(words, maxlen=None):\n",
    "    ids = [convert_word_to_letter_id(w) for w in words]\n",
    "    out = pad_sequences(ids, maxlen=maxlen)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 44, 43, 45, 57]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_word_to_letter_id('abaco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0, ..., 43, 45, 43],\n",
       "        [ 0,  0,  0, ..., 45, 50, 51],\n",
       "        [ 0,  0,  0, ..., 61, 62, 43],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ..., 68, 42, 62],\n",
       "        [ 0,  0,  0, ..., 42, 42, 42],\n",
       "        [ 0,  0,  0, ...,  0,  0,  0]], dtype=int32), 45)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_word = max(max([len(w) for w in it_words]), max([len(w) for w in eng_words]))\n",
    "\n",
    "it_words_ids = convert_dataset_to_idx(it_words, max_len_word)\n",
    "eng_words_ids = convert_dataset_to_idx(eng_words, max_len_word)\n",
    "\n",
    "X = np.r_[it_words_ids, eng_words_ids]\n",
    "X, max_len_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0]*len(it_words) + [1]*len(eng_words))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shuffle\n",
    "rs = np.random.RandomState(123)\n",
    "\n",
    "ids_p = rs.permutation(range(len(y)))\n",
    "\n",
    "X = X[ids_p, :]\n",
    "y = y[ids_p]\n",
    "\n",
    "n_train = int(len(y)*.75)\n",
    "\n",
    "X_tr = X[:n_train, :]\n",
    "X_te = X[n_train:, :]\n",
    "y_tr = y[:n_train]\n",
    "y_te = y[n_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(846087, 45) (282029, 45) (846087,) (282029,) 0.41369859127962016 0.41317382255016327\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, X_te.shape, y_tr.shape, y_te.shape, y_tr.mean(), y_te.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(output_dir+\"/weights-1.01.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 45, 32)            2208      \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 45, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               295936    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 298,401\n",
      "Trainable params: 298,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding = Embedding(len(vocab), n_dim, input_length=max_len_word, mask_zero=True)\n",
    "\n",
    "model.add(embedding) \n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(LSTM(n_rnn, dropout=drop_rnn))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights-2.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 846087 samples, validate on 282029 samples\n",
      "Epoch 1/1\n",
      "166400/846087 [====>.........................] - ETA: 16:08 - loss: 0.1017 - acc: 0.9642"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7a351aa55150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_tr, y_tr, batch_size=batch_size, epochs=1, \n\u001b[0;32m----> 2\u001b[0;31m           verbose=1, validation_data=(X_te, y_te), callbacks=[modelcheckpoint])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/tensorflow-sandbox/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda2/envs/tensorflow-sandbox/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/tensorflow-sandbox/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/tensorflow-sandbox/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/tensorflow-sandbox/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_tr, y_tr, batch_size=batch_size, epochs=1, \n",
    "          verbose=1, validation_data=(X_te, y_te), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_for_word(mod, w):\n",
    "    ids = convert_word_to_letter_id(w)\n",
    "    x = pad_sequences([ids], max_len_word)\n",
    "    p = mod.predict_proba(x.reshape((1, max_len_word)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36486107]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_for_word(model, 'cute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_for_words(mod, W):\n",
    "    idss = [convert_word_to_letter_id(w) for w in W]\n",
    "    xx = pad_sequences(idss, max_len_word)\n",
    "    p = mod.predict_proba(xx)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\tensorflow-sandbox\\lib\\site-packages\\keras\\engine\\sequential.py:247: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.265057  ],\n",
       "       [-0.09119616],\n",
       "       [ 0.04656781],\n",
       "       [ 0.28953287],\n",
       "       [-0.3117346 ],\n",
       "       [-0.27043155],\n",
       "       [ 0.00383865],\n",
       "       [ 0.266654  ],\n",
       "       [ 0.5415539 ],\n",
       "       [ 0.6926975 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_for_words(model, it_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\tensorflow-sandbox\\lib\\site-packages\\keras\\engine\\sequential.py:247: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ssize = 100000\n",
    "\n",
    "sswords = np.random.choice(list(set(it_words).difference(eng_words)), ssize, replace=False)\n",
    "\n",
    "df_ita = pd.DataFrame({'word':sswords})\n",
    "df_ita['pred'] = get_prediction_for_words(model, df_ita['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41509</th>\n",
       "      <td>catalloy</td>\n",
       "      <td>0.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64971</th>\n",
       "      <td>speedway</td>\n",
       "      <td>0.999695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26382</th>\n",
       "      <td>joypad</td>\n",
       "      <td>0.999683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>hydrospeed</td>\n",
       "      <td>0.999570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37814</th>\n",
       "      <td>yurty</td>\n",
       "      <td>0.999389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20489</th>\n",
       "      <td>canyon</td>\n",
       "      <td>0.999189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77655</th>\n",
       "      <td>friendly</td>\n",
       "      <td>0.999070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90356</th>\n",
       "      <td>ryton</td>\n",
       "      <td>0.999065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16148</th>\n",
       "      <td>wallaby</td>\n",
       "      <td>0.999018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36131</th>\n",
       "      <td>cosplay</td>\n",
       "      <td>0.998963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24008</th>\n",
       "      <td>pyrex</td>\n",
       "      <td>0.998865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55313</th>\n",
       "      <td>thyratron</td>\n",
       "      <td>0.998841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90801</th>\n",
       "      <td>cuscus</td>\n",
       "      <td>0.998825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14715</th>\n",
       "      <td>news</td>\n",
       "      <td>0.998816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9617</th>\n",
       "      <td>chantilly</td>\n",
       "      <td>0.998770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72641</th>\n",
       "      <td>yin</td>\n",
       "      <td>0.998707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34192</th>\n",
       "      <td>player</td>\n",
       "      <td>0.998695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88757</th>\n",
       "      <td>potos</td>\n",
       "      <td>0.998454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92582</th>\n",
       "      <td>champenois</td>\n",
       "      <td>0.998265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9817</th>\n",
       "      <td>karakul</td>\n",
       "      <td>0.998224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word      pred\n",
       "41509    catalloy  0.999700\n",
       "64971    speedway  0.999695\n",
       "26382      joypad  0.999683\n",
       "2111   hydrospeed  0.999570\n",
       "37814       yurty  0.999389\n",
       "20489      canyon  0.999189\n",
       "77655    friendly  0.999070\n",
       "90356       ryton  0.999065\n",
       "16148     wallaby  0.999018\n",
       "36131     cosplay  0.998963\n",
       "24008       pyrex  0.998865\n",
       "55313   thyratron  0.998841\n",
       "90801      cuscus  0.998825\n",
       "14715        news  0.998816\n",
       "9617    chantilly  0.998770\n",
       "72641         yin  0.998707\n",
       "34192      player  0.998695\n",
       "88757       potos  0.998454\n",
       "92582  champenois  0.998265\n",
       "9817      karakul  0.998224"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top n parole italiane che suonano inglesi\n",
    "\n",
    "df_ita.sort_values('pred', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79032</th>\n",
       "      <td>sassafrasso</td>\n",
       "      <td>-0.709151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46192</th>\n",
       "      <td>circonstanziero</td>\n",
       "      <td>-0.708358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38499</th>\n",
       "      <td>sguinzagliero</td>\n",
       "      <td>-0.703697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70593</th>\n",
       "      <td>fidecommisso</td>\n",
       "      <td>-0.702689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71936</th>\n",
       "      <td>differenziero</td>\n",
       "      <td>-0.702478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35456</th>\n",
       "      <td>surcompresso</td>\n",
       "      <td>-0.702110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68163</th>\n",
       "      <td>ricetrasmesso</td>\n",
       "      <td>-0.701474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50204</th>\n",
       "      <td>scandagliero</td>\n",
       "      <td>-0.701235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81514</th>\n",
       "      <td>rigermogliero</td>\n",
       "      <td>-0.701039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24022</th>\n",
       "      <td>contraffosso</td>\n",
       "      <td>-0.699609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50146</th>\n",
       "      <td>gargagliero</td>\n",
       "      <td>-0.698966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50765</th>\n",
       "      <td>rigraffiero</td>\n",
       "      <td>-0.698303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92867</th>\n",
       "      <td>circonscritto</td>\n",
       "      <td>-0.697534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39730</th>\n",
       "      <td>consimigliero</td>\n",
       "      <td>-0.697530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76871</th>\n",
       "      <td>avvincigliero</td>\n",
       "      <td>-0.697107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71034</th>\n",
       "      <td>contraddistinto</td>\n",
       "      <td>-0.696871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36977</th>\n",
       "      <td>ridisciogliero</td>\n",
       "      <td>-0.696713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97173</th>\n",
       "      <td>ricompresso</td>\n",
       "      <td>-0.695775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16434</th>\n",
       "      <td>aggranfiero</td>\n",
       "      <td>-0.695644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19064</th>\n",
       "      <td>riaccapigliero</td>\n",
       "      <td>-0.695470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word      pred\n",
       "79032      sassafrasso -0.709151\n",
       "46192  circonstanziero -0.708358\n",
       "38499    sguinzagliero -0.703697\n",
       "70593     fidecommisso -0.702689\n",
       "71936    differenziero -0.702478\n",
       "35456     surcompresso -0.702110\n",
       "68163    ricetrasmesso -0.701474\n",
       "50204     scandagliero -0.701235\n",
       "81514    rigermogliero -0.701039\n",
       "24022     contraffosso -0.699609\n",
       "50146      gargagliero -0.698966\n",
       "50765      rigraffiero -0.698303\n",
       "92867    circonscritto -0.697534\n",
       "39730    consimigliero -0.697530\n",
       "76871    avvincigliero -0.697107\n",
       "71034  contraddistinto -0.696871\n",
       "36977   ridisciogliero -0.696713\n",
       "97173      ricompresso -0.695775\n",
       "16434      aggranfiero -0.695644\n",
       "19064   riaccapigliero -0.695470"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## top n parole che suonano italiane\n",
    "\n",
    "df_ita.sort_values('pred').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.85 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\tensorflow-sandbox\\lib\\site-packages\\keras\\engine\\sequential.py:247: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ssize = 10000\n",
    "\n",
    "sswords = np.random.choice(list(set(eng_words).difference(it_words)), ssize, replace=False)\n",
    "\n",
    "df_eng = pd.DataFrame({'word':sswords})\n",
    "df_eng['pred'] = get_prediction_for_words(model, df_eng['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>arriero</td>\n",
       "      <td>-0.620410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>psilatro</td>\n",
       "      <td>-0.615324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>solariego</td>\n",
       "      <td>-0.556191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>counterembargo</td>\n",
       "      <td>-0.545927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>susso</td>\n",
       "      <td>-0.525332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>sermonettino</td>\n",
       "      <td>-0.514565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>zaburro</td>\n",
       "      <td>-0.505237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>zorrillo</td>\n",
       "      <td>-0.503622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>overgo</td>\n",
       "      <td>-0.482432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>cururo</td>\n",
       "      <td>-0.461673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>caraco</td>\n",
       "      <td>-0.452072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>ailuro</td>\n",
       "      <td>-0.435973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>renegado</td>\n",
       "      <td>-0.429439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>mirligo</td>\n",
       "      <td>-0.424174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>speedo</td>\n",
       "      <td>-0.422449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>estrangelo</td>\n",
       "      <td>-0.415440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8091</th>\n",
       "      <td>chivari</td>\n",
       "      <td>-0.412673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>coccobacilli</td>\n",
       "      <td>-0.409704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>scalado</td>\n",
       "      <td>-0.407587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>patrico</td>\n",
       "      <td>-0.406353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word      pred\n",
       "855          arriero -0.620410\n",
       "1024        psilatro -0.615324\n",
       "324        solariego -0.556191\n",
       "1885  counterembargo -0.545927\n",
       "7937           susso -0.525332\n",
       "6598    sermonettino -0.514565\n",
       "721          zaburro -0.505237\n",
       "3011        zorrillo -0.503622\n",
       "9857          overgo -0.482432\n",
       "4457          cururo -0.461673\n",
       "5552          caraco -0.452072\n",
       "4664          ailuro -0.435973\n",
       "3406        renegado -0.429439\n",
       "8434         mirligo -0.424174\n",
       "3084          speedo -0.422449\n",
       "9286      estrangelo -0.415440\n",
       "8091         chivari -0.412673\n",
       "1414    coccobacilli -0.409704\n",
       "7579         scalado -0.407587\n",
       "1141         patrico -0.406353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 english words that sound italian\n",
    "\n",
    "df_eng.sort_values('pred').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>do.</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>B.D.</td>\n",
       "      <td>0.999969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>D.S.M.</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q.</td>\n",
       "      <td>0.999954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>q.e.</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>simplicity's</td>\n",
       "      <td>0.999941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>liability's</td>\n",
       "      <td>0.999935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>lily's</td>\n",
       "      <td>0.999931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>freq.</td>\n",
       "      <td>0.999930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>Cryptorhynchus</td>\n",
       "      <td>0.999928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>trolley's</td>\n",
       "      <td>0.999928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Ltd.</td>\n",
       "      <td>0.999927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>orgy's</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>burglary's</td>\n",
       "      <td>0.999925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>Eliz.</td>\n",
       "      <td>0.999924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>sanctuary's</td>\n",
       "      <td>0.999924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>rhythm-and-blues</td>\n",
       "      <td>0.999922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>Ampelosicyos</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>Trans-indus</td>\n",
       "      <td>0.999919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>Whit-Tuesday</td>\n",
       "      <td>0.999916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word      pred\n",
       "9288               do.  0.999972\n",
       "3338              B.D.  0.999969\n",
       "4940            D.S.M.  0.999968\n",
       "31                  Q.  0.999954\n",
       "3374              q.e.  0.999946\n",
       "4886      simplicity's  0.999941\n",
       "749        liability's  0.999935\n",
       "1398            lily's  0.999931\n",
       "6890             freq.  0.999930\n",
       "2807    Cryptorhynchus  0.999928\n",
       "1075         trolley's  0.999928\n",
       "292               Ltd.  0.999927\n",
       "787             orgy's  0.999925\n",
       "6           burglary's  0.999925\n",
       "1841             Eliz.  0.999924\n",
       "5586       sanctuary's  0.999924\n",
       "8954  rhythm-and-blues  0.999922\n",
       "9397      Ampelosicyos  0.999919\n",
       "4835       Trans-indus  0.999919\n",
       "1104      Whit-Tuesday  0.999916"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 20 english words that sound very english\n",
    "\n",
    "df_eng.sort_values('pred', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\tensorflow-sandbox\\lib\\site-packages\\keras\\engine\\sequential.py:247: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.4148296]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_for_word(model, 'pappero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9980908]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_for_word(model, 'supercalifragilisticexpialidocious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 249.00 337.00\" width=\"249pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-333 245,-333 245,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1989977792752 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1989977792752</title>\n",
       "<polygon fill=\"none\" points=\"39,-219.5 39,-255.5 202,-255.5 202,-219.5 39,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-233.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 1989977793368 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1989977793368</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 241,-182.5 241,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-160.8\">spatial_dropout1d_1: SpatialDropout1D</text>\n",
       "</g>\n",
       "<!-- 1989977792752&#45;&gt;1989977793368 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1989977792752-&gt;1989977793368</title>\n",
       "<path d=\"M120.5,-219.313C120.5,-211.289 120.5,-201.547 120.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"124,-192.529 120.5,-182.529 117,-192.529 124,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1989977793648 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1989977793648</title>\n",
       "<polygon fill=\"none\" points=\"71.5,-73.5 71.5,-109.5 169.5,-109.5 169.5,-73.5 71.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-87.8\">lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 1989977793368&#45;&gt;1989977793648 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1989977793368-&gt;1989977793648</title>\n",
       "<path d=\"M120.5,-146.313C120.5,-138.289 120.5,-128.547 120.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"124,-119.529 120.5,-109.529 117,-119.529 124,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1989581161024 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1989581161024</title>\n",
       "<polygon fill=\"none\" points=\"68.5,-0.5 68.5,-36.5 172.5,-36.5 172.5,-0.5 68.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 1989977793648&#45;&gt;1989581161024 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1989977793648-&gt;1989581161024</title>\n",
       "<path d=\"M120.5,-73.3129C120.5,-65.2895 120.5,-55.5475 120.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"124,-46.5288 120.5,-36.5288 117,-46.5289 124,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1989977792808 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1989977792808</title>\n",
       "<polygon fill=\"none\" points=\"68.5,-292.5 68.5,-328.5 172.5,-328.5 172.5,-292.5 68.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-306.8\">1989977792808</text>\n",
       "</g>\n",
       "<!-- 1989977792808&#45;&gt;1989977792752 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1989977792808-&gt;1989977792752</title>\n",
       "<path d=\"M120.5,-292.313C120.5,-284.289 120.5,-274.547 120.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"124,-265.529 120.5,-255.529 117,-265.529 124,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import pydot as pyd\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "keras.utils.vis_utils.pydot = pyd\n",
    "\n",
    "#Visualize Model\n",
    "\n",
    "def visualize_model(model):\n",
    "  return SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "#create your model\n",
    "#then call the function on your model\n",
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.get_layer('embedding_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-sandbox]",
   "language": "python",
   "name": "conda-env-tensorflow-sandbox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
